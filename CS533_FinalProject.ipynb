{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvIAFouLkA+SL9g4MiDGUe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasti-Jalali/PPI-Classification/blob/main/CS533_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YYfI7KphZO0h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/drive/MyDrive/3D Computer Vision/final_project"
      ],
      "metadata": {
        "id": "qSs3h8IMZQGF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clRnZnnLZUVf",
        "outputId": "2ceeb5e4-bf03-49d9-8f94-e1ac94e770e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv, JumpingKnowledge\n",
        "from torch_geometric.datasets import PPI\n",
        "from torch_geometric.loader import DataLoader"
      ],
      "metadata": {
        "id": "nWhbtBwD-jFJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Student Model\n",
        "# -------------------------\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, use_jk=False):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.use_jk = use_jk\n",
        "\n",
        "        # GIN Layers\n",
        "        self.gin_convs = nn.ModuleList()\n",
        "        self.gin_convs.append(\n",
        "            GINConv(nn.Sequential(\n",
        "                nn.Linear(in_channels, hidden_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_channels, hidden_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(hidden_channels)\n",
        "            ))\n",
        "        )\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.gin_convs.append(\n",
        "                GINConv(nn.Sequential(\n",
        "                    nn.Linear(hidden_channels, hidden_channels),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hidden_channels, hidden_channels),\n",
        "                    nn.ReLU(),\n",
        "                    nn.BatchNorm1d(hidden_channels)\n",
        "                ))\n",
        "            )\n",
        "\n",
        "        # Jumping Knowledge (optional)\n",
        "        if self.use_jk:\n",
        "            self.jk = JumpingKnowledge(mode='cat')\n",
        "            self.lin1 = nn.Linear(num_layers * hidden_channels, hidden_channels)\n",
        "        else:\n",
        "            self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        embeddings = []\n",
        "        for conv in self.gin_convs:\n",
        "            x = conv(x, edge_index)\n",
        "            embeddings.append(x)\n",
        "\n",
        "        if self.use_jk:\n",
        "            x = self.jk(embeddings)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)  # Output node classification logits\n",
        "        return x"
      ],
      "metadata": {
        "id": "cQW9rML8-pfZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Teacher Model\n",
        "# -------------------------\n",
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self, student_model):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        # Clone student model structure\n",
        "        self.model = StudentModel(\n",
        "            in_channels=student_model.gin_convs[0].nn[0].in_features,\n",
        "            hidden_channels=student_model.gin_convs[0].nn[0].out_features,\n",
        "            out_channels=student_model.lin2.out_features,\n",
        "            num_layers=len(student_model.gin_convs),\n",
        "            use_jk=student_model.use_jk\n",
        "        )\n",
        "        self.model.load_state_dict(student_model.state_dict())  # Initialize with student weights\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update(self, student_model, alpha=0.99):\n",
        "        \"\"\"Update teacher parameters using EMA.\"\"\"\n",
        "        for teacher_param, student_param in zip(self.model.parameters(), student_model.parameters()):\n",
        "            teacher_param.data = alpha * teacher_param.data + (1 - alpha) * student_param.data\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.model(x, edge_index)"
      ],
      "metadata": {
        "id": "psAdlsnM-r1o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Semi-Supervised Loss Function\n",
        "# -------------------------\n",
        "def graph_consistency_loss(student_out, teacher_out, mask):\n",
        "    \"\"\"Calculate consistency loss using adjacency similarity.\"\"\"\n",
        "    student_probs = F.softmax(student_out[mask], dim=1)\n",
        "    teacher_probs = F.softmax(teacher_out[mask], dim=1)\n",
        "\n",
        "    student_adj = torch.mm(student_probs, student_probs.T)\n",
        "    teacher_adj = torch.mm(teacher_probs, teacher_probs.T)\n",
        "\n",
        "    return F.mse_loss(student_adj, teacher_adj)\n",
        "\n",
        "def semi_supervised_loss(student_out, teacher_out, labels, labeled_mask, unlabeled_mask, lambda_con=0.1):\n",
        "    \"\"\"Combined supervised and consistency loss.\"\"\"\n",
        "    # sup_loss = F.cross_entropy(student_out[labeled_mask], labels[labeled_mask])\n",
        "    # sup_loss = torch.nn.BCEWithLogitsLoss(student_out[labeled_mask], labels[labeled_mask])\n",
        "    bce_loss = nn.BCEWithLogitsLoss()\n",
        "    sup_loss = bce_loss(student_out[labeled_mask], labels[labeled_mask])\n",
        "\n",
        "    con_loss = graph_consistency_loss(student_out, teacher_out, unlabeled_mask)\n",
        "    return sup_loss + lambda_con * con_loss"
      ],
      "metadata": {
        "id": "-BmOAYtP-tr6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Training Framework\n",
        "# -------------------------\n",
        "class SemiGNNFrameworkPPI:\n",
        "    def __init__(self, student_model, teacher_model, device):\n",
        "        self.student = student_model.to(device)\n",
        "        self.teacher = teacher_model.to(device)\n",
        "        self.device = device\n",
        "        self.optimizer = torch.optim.Adam(self.student.parameters(), lr=0.005)\n",
        "        self.lambda_con = 0.1\n",
        "\n",
        "    def train_step(self, loader):\n",
        "        \"\"\"Train student and update teacher model.\"\"\"\n",
        "        self.student.train()\n",
        "        self.teacher.eval()\n",
        "        total_loss = 0\n",
        "\n",
        "        for data in loader:\n",
        "            data = data.to(self.device)\n",
        "            labeled_mask = data.train_mask\n",
        "            unlabeled_mask = ~data.train_mask\n",
        "\n",
        "            # Forward pass\n",
        "            student_out = self.student(data.x, data.edge_index)\n",
        "            with torch.no_grad():\n",
        "                teacher_out = self.teacher(data.x, data.edge_index)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = semi_supervised_loss(student_out, teacher_out, data.y, labeled_mask, unlabeled_mask, self.lambda_con)\n",
        "\n",
        "            # Backpropagation\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Update teacher model\n",
        "        self.teacher.update(self.student)\n",
        "        return total_loss / len(loader)\n",
        "\n",
        "\n",
        "    def evaluate(self, loader):\n",
        "      \"\"\"Evaluate the student model for multi-label node classification.\"\"\"\n",
        "      self.student.eval()\n",
        "      total_correct, total_labels = 0, 0\n",
        "\n",
        "      for data in loader:\n",
        "          data = data.to(self.device)\n",
        "          with torch.no_grad():\n",
        "              out = self.student(data.x, data.edge_index)  # Raw logits\n",
        "              prob = torch.sigmoid(out)                   # Probabilities (0 to 1)\n",
        "              pred = (prob > 0.5).long()                  # Binarize predictions\n",
        "              # print(data.val_mask.shape)\n",
        "              # print(pred.shape)\n",
        "              # print(data.y.shape)\n",
        "\n",
        "              # Validation mask and multi-label accuracy\n",
        "              correct = (pred[data.val_mask] == data.y[data.val_mask]).sum().item()\n",
        "              total_correct += correct\n",
        "              total_labels += data.val_mask.sum().item() * data.y.size(1)  # Total labels (nodes * 121)\n",
        "\n",
        "      accuracy = total_correct / total_labels\n",
        "      return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "_U7Qjgss-2QH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Main Script\n",
        "# -------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Load PPI dataset\n",
        "train_dataset = PPI(root='data/PPI', split='train')\n",
        "val_dataset = PPI(root='data/PPI', split='val')\n",
        "test_dataset = PPI(root='data/PPI', split='test')\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def create_train_mask(data, train_ratio=0.9):\n",
        "    \"\"\"\n",
        "    Create a train_mask for nodes in a graph.\n",
        "    :param data: A graph in the PPI dataset (torch_geometric.data.Data).\n",
        "    :param train_ratio: Fraction of nodes to use for training.\n",
        "    :return: train_mask (torch.Tensor)\n",
        "    \"\"\"\n",
        "    num_nodes = data.x.size(0)  # Total number of nodes\n",
        "    num_train = int(train_ratio * num_nodes)  # Number of training nodes\n",
        "\n",
        "    # Randomly permute indices and select train nodes\n",
        "    perm = torch.randperm(num_nodes)\n",
        "    train_indices = perm[:num_train]\n",
        "\n",
        "    # Initialize train_mask\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    train_mask[train_indices] = True\n",
        "    return train_mask\n",
        "\n",
        "# Update train_dataset with train_mask\n",
        "updated_train_dataset = []\n",
        "for graph in train_dataset:\n",
        "    train_mask = create_train_mask(graph, train_ratio=0.9)\n",
        "    updated_graph = Data(\n",
        "        x=graph.x,\n",
        "        edge_index=graph.edge_index,\n",
        "        y=graph.y,\n",
        "        train_mask=train_mask\n",
        "    )\n",
        "    updated_train_dataset.append(updated_graph)\n",
        "\n",
        "# Update validation and test datasets\n",
        "updated_val_dataset = []\n",
        "for graph in val_dataset:\n",
        "    val_mask = create_train_mask(graph, train_ratio=0.9)\n",
        "    updated_graph = Data(\n",
        "        x=graph.x,\n",
        "        edge_index=graph.edge_index,\n",
        "        y=graph.y,\n",
        "        val_mask=val_mask\n",
        "    )\n",
        "    updated_val_dataset.append(updated_graph)\n",
        "\n",
        "updated_test_dataset = []\n",
        "for graph in test_dataset:\n",
        "    val_mask = create_train_mask(graph, train_ratio=0.9)\n",
        "    updated_graph = Data(\n",
        "        x=graph.x,\n",
        "        edge_index=graph.edge_index,\n",
        "        y=graph.y,\n",
        "        val_mask=val_mask\n",
        "    )\n",
        "    updated_test_dataset.append(updated_graph)\n",
        "\n",
        "\n",
        "# print(f\"Train_mask example: {updated_train_dataset[0].train_mask}\")\n",
        "# print(f\"Val_mask example: {updated_val_dataset[0].val_mask}\")\n",
        "# print(f\"Test_mask example: {updated_test_dataset[0].test_mask}\")\n",
        "\n",
        "train_loader = DataLoader(updated_train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(updated_val_dataset, batch_size=2, shuffle=False)\n",
        "test_loader = DataLoader(updated_test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# Initialize models\n",
        "student_model = StudentModel(in_channels=train_dataset.num_features, hidden_channels=256,\n",
        "                             out_channels=train_dataset.num_classes, num_layers=3, use_jk=True)\n",
        "teacher_model = TeacherModel(student_model)\n",
        "\n",
        "# Initialize framework\n",
        "framework = SemiGNNFrameworkPPI(student_model, teacher_model, device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    train_loss = framework.train_step(train_loader)\n",
        "    val_accuracy = framework.evaluate(val_loader)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Testing\n",
        "test_accuracy = framework.evaluate(test_loader)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkBODMuYwaxu",
        "outputId": "64ce478e-782a-4dcc-f8f7-235a80f79f63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.5760, Validation Accuracy: 0.7647\n",
            "Epoch 2: Train Loss: 0.4721, Validation Accuracy: 0.7870\n",
            "Epoch 3: Train Loss: 0.4014, Validation Accuracy: 0.8206\n",
            "Epoch 4: Train Loss: 0.3492, Validation Accuracy: 0.8486\n",
            "Epoch 5: Train Loss: 0.3056, Validation Accuracy: 0.8619\n",
            "Epoch 6: Train Loss: 0.2763, Validation Accuracy: 0.8736\n",
            "Epoch 7: Train Loss: 0.2394, Validation Accuracy: 0.8906\n",
            "Epoch 8: Train Loss: 0.2062, Validation Accuracy: 0.9039\n",
            "Epoch 9: Train Loss: 0.1914, Validation Accuracy: 0.9069\n",
            "Epoch 10: Train Loss: 0.1658, Validation Accuracy: 0.9182\n",
            "Epoch 11: Train Loss: 0.1463, Validation Accuracy: 0.9272\n",
            "Epoch 12: Train Loss: 0.1307, Validation Accuracy: 0.9321\n",
            "Epoch 13: Train Loss: 0.1165, Validation Accuracy: 0.9369\n",
            "Epoch 14: Train Loss: 0.1060, Validation Accuracy: 0.9431\n",
            "Epoch 15: Train Loss: 0.0948, Validation Accuracy: 0.9481\n",
            "Epoch 16: Train Loss: 0.0871, Validation Accuracy: 0.9498\n",
            "Epoch 17: Train Loss: 0.0815, Validation Accuracy: 0.9429\n",
            "Epoch 18: Train Loss: 0.0773, Validation Accuracy: 0.9555\n",
            "Epoch 19: Train Loss: 0.0657, Validation Accuracy: 0.9585\n",
            "Epoch 20: Train Loss: 0.0647, Validation Accuracy: 0.9560\n",
            "Epoch 21: Train Loss: 0.0719, Validation Accuracy: 0.9531\n",
            "Epoch 22: Train Loss: 0.0635, Validation Accuracy: 0.9572\n",
            "Epoch 23: Train Loss: 0.0580, Validation Accuracy: 0.9591\n",
            "Epoch 24: Train Loss: 0.0516, Validation Accuracy: 0.9635\n",
            "Epoch 25: Train Loss: 0.0492, Validation Accuracy: 0.9644\n",
            "Epoch 26: Train Loss: 0.0412, Validation Accuracy: 0.9696\n",
            "Epoch 27: Train Loss: 0.0383, Validation Accuracy: 0.9709\n",
            "Epoch 28: Train Loss: 0.0348, Validation Accuracy: 0.9712\n",
            "Epoch 29: Train Loss: 0.0320, Validation Accuracy: 0.9735\n",
            "Epoch 30: Train Loss: 0.0304, Validation Accuracy: 0.9734\n",
            "Epoch 31: Train Loss: 0.0290, Validation Accuracy: 0.9734\n",
            "Epoch 32: Train Loss: 0.0291, Validation Accuracy: 0.9736\n",
            "Epoch 33: Train Loss: 0.0280, Validation Accuracy: 0.9730\n",
            "Epoch 34: Train Loss: 0.0271, Validation Accuracy: 0.9717\n",
            "Epoch 35: Train Loss: 0.0293, Validation Accuracy: 0.9691\n",
            "Epoch 36: Train Loss: 0.0338, Validation Accuracy: 0.9685\n",
            "Epoch 37: Train Loss: 0.0300, Validation Accuracy: 0.9736\n",
            "Epoch 38: Train Loss: 0.0345, Validation Accuracy: 0.9679\n",
            "Epoch 39: Train Loss: 0.0350, Validation Accuracy: 0.9723\n",
            "Epoch 40: Train Loss: 0.0321, Validation Accuracy: 0.9724\n",
            "Epoch 41: Train Loss: 0.0298, Validation Accuracy: 0.9753\n",
            "Epoch 42: Train Loss: 0.0251, Validation Accuracy: 0.9769\n",
            "Epoch 43: Train Loss: 0.0243, Validation Accuracy: 0.9768\n",
            "Epoch 44: Train Loss: 0.0224, Validation Accuracy: 0.9764\n",
            "Epoch 45: Train Loss: 0.0251, Validation Accuracy: 0.9724\n",
            "Epoch 46: Train Loss: 0.0270, Validation Accuracy: 0.9756\n",
            "Epoch 47: Train Loss: 0.0252, Validation Accuracy: 0.9741\n",
            "Epoch 48: Train Loss: 0.0241, Validation Accuracy: 0.9766\n",
            "Epoch 49: Train Loss: 0.0225, Validation Accuracy: 0.9765\n",
            "Epoch 50: Train Loss: 0.0228, Validation Accuracy: 0.9749\n",
            "Test Accuracy: 0.9816\n"
          ]
        }
      ]
    }
  ]
}