{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"YYfI7KphZO0h","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:41.901256Z","iopub.execute_input":"2024-12-18T20:28:41.901717Z","iopub.status.idle":"2024-12-18T20:28:41.905898Z","shell.execute_reply.started":"2024-12-18T20:28:41.901677Z","shell.execute_reply":"2024-12-18T20:28:41.904801Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# cd /content/drive/MyDrive/3D Computer Vision/final_project","metadata":{"id":"qSs3h8IMZQGF","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:41.907243Z","iopub.execute_input":"2024-12-18T20:28:41.907617Z","iopub.status.idle":"2024-12-18T20:28:41.922083Z","shell.execute_reply.started":"2024-12-18T20:28:41.907584Z","shell.execute_reply":"2024-12-18T20:28:41.921214Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clRnZnnLZUVf","outputId":"9972ba07-25d1-44a1-d7d2-269f02fed927","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:41.924151Z","iopub.execute_input":"2024-12-18T20:28:41.924392Z","iopub.status.idle":"2024-12-18T20:28:45.626204Z","shell.execute_reply.started":"2024-12-18T20:28:41.924372Z","shell.execute_reply":"2024-12-18T20:28:45.624916Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.5)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"pip show torch_sparse","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7bKga9NBR2c","outputId":"ec3e3918-b936-40c3-8755-be920b6b8a30","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:45.627849Z","iopub.execute_input":"2024-12-18T20:28:45.628208Z","iopub.status.idle":"2024-12-18T20:28:46.252042Z","shell.execute_reply.started":"2024-12-18T20:28:45.628177Z","shell.execute_reply":"2024-12-18T20:28:46.250637Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Package(s) not found: torch_sparse\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GINConv, JumpingKnowledge, GCNConv\nfrom torch_geometric.datasets import PPI\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.utils import dense_to_sparse","metadata":{"id":"nWhbtBwD-jFJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:46.262751Z","iopub.execute_input":"2024-12-18T20:28:46.263229Z","iopub.status.idle":"2024-12-18T20:28:46.280020Z","shell.execute_reply.started":"2024-12-18T20:28:46.263194Z","shell.execute_reply":"2024-12-18T20:28:46.278965Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# -------------------------\n# Label Learner Component\n# -------------------------\nclass LabelGraphLearner(nn.Module):\n    def __init__(self, num_labels):\n        super(LabelGraphLearner, self).__init__()\n        self.label_adj = nn.Parameter(torch.randn(num_labels, num_labels))  # Learnable adjacency matrix\n\n    def forward(self):\n        \"\"\"\n        Learn the label adjacency matrix as edge probabilities.\n        :return: Learned label adjacency matrix (softmax-normalized).\n        \"\"\"\n        adj = torch.sigmoid(self.label_adj)  # Map to [0, 1] as edge probabilities\n        return adj\n\nclass LabelGCN(nn.Module):\n    def __init__(self, num_labels, hidden_channels):\n        super(LabelGCN, self).__init__()\n        self.conv1 = GCNConv(num_labels, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n\n    def forward(self, label_adj):\n        \"\"\"\n        Propagate through the label graph using GCN.\n        :param label_adj: Adjacency matrix for labels.\n        :return: Refined label embeddings.\n        \"\"\"\n        x = torch.eye(label_adj.size(0)).to(label_adj.device)  # One-hot encoding for labels\n        edge_index, _ = dense_to_sparse(label_adj)  # Convert adjacency matrix to edge_index format\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.conv2(x, edge_index)\n        return x\n","metadata":{"id":"d0uxiT5lpobb","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:46.253343Z","iopub.execute_input":"2024-12-18T20:28:46.253691Z","iopub.status.idle":"2024-12-18T20:28:46.261539Z","shell.execute_reply.started":"2024-12-18T20:28:46.253656Z","shell.execute_reply":"2024-12-18T20:28:46.260279Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# -------------------------\n# Student Model\n# -------------------------\nclass StudentModel(nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, use_jk=False):\n        super(StudentModel, self).__init__()\n        self.use_jk = use_jk\n\n        # GIN Layers for node embeddings\n        self.gin_convs = nn.ModuleList()\n        self.gin_convs.append(\n            GINConv(nn.Sequential(\n                nn.Linear(in_channels, hidden_channels),\n                nn.ReLU(),\n                nn.Linear(hidden_channels, hidden_channels),\n                nn.ReLU(),\n                nn.BatchNorm1d(hidden_channels)\n            ))\n        )\n        for _ in range(num_layers - 1):\n            self.gin_convs.append(\n                GINConv(nn.Sequential(\n                    nn.Linear(hidden_channels, hidden_channels),\n                    nn.ReLU(),\n                    nn.Linear(hidden_channels, hidden_channels),\n                    nn.ReLU(),\n                    nn.BatchNorm1d(hidden_channels)\n                ))\n            )\n\n        if self.use_jk:\n            self.jk = JumpingKnowledge(mode='cat')\n            self.lin1 = nn.Linear(num_layers * hidden_channels, hidden_channels)\n        else:\n            self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n\n        # Label learning components\n        self.label_learner = LabelGraphLearner(out_channels)\n        self.label_gcn = LabelGCN(out_channels, hidden_channels)\n\n        # Graph-based interaction layer\n        self.node_label_interaction = GCNConv(hidden_channels, out_channels)\n\n    def forward(self, x, edge_index):\n        \"\"\"\n        Forward pass for the student model.\n        :param x: Node features.\n        :param edge_index: Graph structure.\n        :return: Node-label logits and label adjacency matrix.\n        \"\"\"\n        # Node embeddings\n        embeddings = []\n        for conv in self.gin_convs:\n            x = conv(x, edge_index)\n            embeddings.append(x)\n\n        if self.use_jk:\n            x = self.jk(embeddings)\n        x = F.relu(self.lin1(x))  # Node embeddings (shape: [num_nodes, hidden_channels])\n\n        # Label embeddings\n        label_adj = self.label_learner()  # Learn the label graph\n        label_embeddings = self.label_gcn(label_adj)  # Refine label embeddings (shape: [num_labels, hidden_channels])\n\n        # Combine node and label embeddings into a joint graph\n        # Create a node-label interaction graph\n        num_nodes = x.size(0)\n        num_labels = label_embeddings.size(0)\n\n        # Concatenate node and label embeddings\n        combined_embeddings = torch.cat([x, label_embeddings], dim=0)  # Shape: [num_nodes + num_labels, hidden_channels]\n\n        # Create interaction edges between all nodes and labels\n        node_indices = torch.arange(num_nodes)\n        label_indices = torch.arange(num_labels) + num_nodes\n        interaction_edges = torch.stack(torch.meshgrid(node_indices, label_indices)).reshape(2, -1).to(edge_index.device)\n\n        # Pass through GCN for node-label interaction\n        interaction_logits = self.node_label_interaction(combined_embeddings, interaction_edges)  # Shape: [num_nodes + num_labels, out_channels]\n\n        # Extract node-label logits\n        node_label_logits = interaction_logits[:num_nodes]  # Shape: [num_nodes, num_labels]\n\n        return node_label_logits\n","metadata":{"id":"cQW9rML8-pfZ","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:46.281159Z","iopub.execute_input":"2024-12-18T20:28:46.281508Z","iopub.status.idle":"2024-12-18T20:28:46.298174Z","shell.execute_reply.started":"2024-12-18T20:28:46.281475Z","shell.execute_reply":"2024-12-18T20:28:46.297220Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# -------------------------\n# Teacher Model\n# -------------------------\nclass TeacherModel(nn.Module):\n    def __init__(self, student_model):\n        super(TeacherModel, self).__init__()\n        # Clone student model structure\n        self.model = StudentModel(\n            in_channels=student_model.gin_convs[0].nn[0].in_features,\n            hidden_channels=student_model.gin_convs[0].nn[0].out_features,\n            out_channels=student_model.label_learner.label_adj.shape[0],\n            num_layers=len(student_model.gin_convs),\n            use_jk=student_model.use_jk\n        )\n        self.model.load_state_dict(student_model.state_dict())  # Initialize with student weights\n\n    @torch.no_grad()\n    def update(self, student_model, alpha=0.99):\n        \"\"\"Update teacher parameters using EMA.\"\"\"\n        for teacher_param, student_param in zip(self.model.parameters(), student_model.parameters()):\n            teacher_param.data = alpha * teacher_param.data + (1 - alpha) * student_param.data\n\n    def forward(self, x, edge_index):\n        return self.model(x, edge_index)","metadata":{"id":"psAdlsnM-r1o","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:46.299184Z","iopub.execute_input":"2024-12-18T20:28:46.299475Z","iopub.status.idle":"2024-12-18T20:28:46.319343Z","shell.execute_reply.started":"2024-12-18T20:28:46.299452Z","shell.execute_reply":"2024-12-18T20:28:46.318364Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# -------------------------\n# Semi-Supervised Loss Function\n# -------------------------\ndef graph_consistency_loss(student_out, teacher_out, mask):\n    \"\"\"Calculate consistency loss using adjacency similarity.\"\"\"\n    student_probs = F.softmax(student_out[mask], dim=1)\n    teacher_probs = F.softmax(teacher_out[mask], dim=1)\n\n    student_adj = torch.mm(student_probs, student_probs.T)\n    teacher_adj = torch.mm(teacher_probs, teacher_probs.T)\n\n    return F.mse_loss(student_adj, teacher_adj)\n\ndef semi_supervised_loss(student_out, teacher_out, labels, labeled_mask, unlabeled_mask, lambda_con=0.1):\n    \"\"\"Combined supervised and consistency loss.\"\"\"\n    # sup_loss = F.cross_entropy(student_out[labeled_mask], labels[labeled_mask])\n    # sup_loss = torch.nn.BCEWithLogitsLoss(student_out[labeled_mask], labels[labeled_mask])\n    bce_loss = nn.BCEWithLogitsLoss()\n    sup_loss = bce_loss(student_out[labeled_mask], labels[labeled_mask])\n\n    con_loss = graph_consistency_loss(student_out, teacher_out, unlabeled_mask)\n    return sup_loss + lambda_con * con_loss","metadata":{"id":"-BmOAYtP-tr6","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:46.322603Z","iopub.execute_input":"2024-12-18T20:28:46.322994Z","iopub.status.idle":"2024-12-18T20:28:46.349357Z","shell.execute_reply.started":"2024-12-18T20:28:46.322937Z","shell.execute_reply":"2024-12-18T20:28:46.348300Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# -------------------------\n# Training Framework\n# -------------------------\nclass SemiGNNFrameworkPPI:\n    def __init__(self, student_model, teacher_model, device):\n        self.student = student_model.to(device)\n        self.teacher = teacher_model.to(device)\n        self.device = device\n        self.optimizer = torch.optim.Adam(self.student.parameters(), lr=0.001)\n        self.lambda_con = 0.1\n\n    def train_step(self, loader):\n        self.student.train()\n        self.teacher.eval()\n        total_loss = 0\n\n        for data in loader:\n            data = data.to(self.device)\n            labeled_mask = data.train_mask\n            unlabeled_mask = ~data.train_mask\n\n            # Student forward pass\n            student_out = self.student(data.x, data.edge_index)\n\n            # Teacher forward pass\n            with torch.no_grad():\n                teacher_out = self.teacher(data.x, data.edge_index)\n\n            # Compute loss\n            loss = semi_supervised_loss(\n                student_out, teacher_out, data.y, labeled_mask, unlabeled_mask, self.lambda_con\n            )\n\n            # Backpropagation\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            total_loss += loss.item()\n\n        # Update teacher model\n        self.teacher.update(self.student)\n        return total_loss / len(loader)\n\n\n    def evaluate(self, loader):\n      \"\"\"Evaluate the student model for multi-label node classification.\"\"\"\n      self.student.eval()\n      total_correct, total_labels = 0, 0\n\n      for data in loader:\n          data = data.to(self.device)\n          with torch.no_grad():\n              out = self.student(data.x, data.edge_index)  # Raw logits\n              prob = torch.sigmoid(out)                   # Probabilities (0 to 1)\n              pred = (prob > 0.5).long()                  # Binarize predictions\n              # print(data.val_mask.shape)\n              # print(pred.shape)\n              # print(data.y.shape)\n\n              # Validation mask and multi-label accuracy\n              correct = (pred == data.y).sum().item()\n              total_correct += correct\n              total_labels += data.y.size(0) * data.y.size(1)  # Total labels (nodes * 121)\n\n      accuracy = total_correct / total_labels\n      return accuracy\n\n","metadata":{"id":"_U7Qjgss-2QH","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:46.350526Z","iopub.execute_input":"2024-12-18T20:28:46.350873Z","iopub.status.idle":"2024-12-18T20:28:46.374315Z","shell.execute_reply.started":"2024-12-18T20:28:46.350851Z","shell.execute_reply":"2024-12-18T20:28:46.373243Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# -------------------------\n# Main Script\n# -------------------------\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Load PPI dataset\ntrain_dataset = PPI(root='data/PPI', split='train')\nval_dataset = PPI(root='data/PPI', split='val')\ntest_dataset = PPI(root='data/PPI', split='test')\n\nfrom torch_geometric.data import Data\n\ndef create_train_mask(data, train_ratio=0.9):\n    \"\"\"\n    Create a train_mask for nodes in a graph.\n    :param data: A graph in the PPI dataset (torch_geometric.data.Data).\n    :param train_ratio: Fraction of nodes to use for training.\n    :return: train_mask (torch.Tensor)\n    \"\"\"\n    num_nodes = data.x.size(0)  # Total number of nodes\n    num_train = int(train_ratio * num_nodes)  # Number of training nodes\n\n    # Randomly permute indices and select train nodes\n    perm = torch.randperm(num_nodes)\n    train_indices = perm[:num_train]\n\n    # Initialize train_mask\n    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n    train_mask[train_indices] = True\n    return train_mask\n\n# Update train_dataset with train_mask\nupdated_train_dataset = []\nfor graph in train_dataset:\n    train_mask = create_train_mask(graph, train_ratio=0.05)\n    updated_graph = Data(\n        x=graph.x,\n        edge_index=graph.edge_index,\n        y=graph.y,\n        train_mask=train_mask\n    )\n    updated_train_dataset.append(updated_graph)\n\n\n# print(f\"Train_mask example: {updated_train_dataset[0].train_mask}\")\n\ntrain_loader = DataLoader(updated_train_dataset, batch_size=2, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n\n# Initialize models\nstudent_model = StudentModel(in_channels=train_dataset.num_features, hidden_channels=512,\n                             out_channels=train_dataset.num_classes, num_layers=3, use_jk=True)\nteacher_model = TeacherModel(student_model)\n\n# Initialize framework\nframework = SemiGNNFrameworkPPI(student_model, teacher_model, device)\n\n# Training loop\nfor epoch in range(50):\n    train_loss = framework.train_step(train_loader)\n    val_accuracy = framework.evaluate(val_loader)\n    print(f\"Epoch {epoch+1:02d}: Train Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n\n# Testing\ntest_accuracy = framework.evaluate(test_loader)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kkBODMuYwaxu","outputId":"aa54e3e1-c0f7-4214-c9ca-d24759b6b62c","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T20:28:46.375387Z","iopub.execute_input":"2024-12-18T20:28:46.375807Z","iopub.status.idle":"2024-12-18T20:29:44.625369Z","shell.execute_reply.started":"2024-12-18T20:28:46.375769Z","shell.execute_reply":"2024-12-18T20:29:44.624421Z"}},"outputs":[{"name":"stderr","text":"Downloading https://data.dgl.ai/dataset/ppi.zip\nExtracting data/PPI/ppi.zip\nProcessing...\nDone!\n/usr/local/lib/python3.10/dist-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01: Train Loss: 0.6159, Validation Accuracy: 0.6921\nEpoch 02: Train Loss: 0.5217, Validation Accuracy: 0.7611\nEpoch 03: Train Loss: 0.4636, Validation Accuracy: 0.7780\nEpoch 04: Train Loss: 0.4050, Validation Accuracy: 0.7844\nEpoch 05: Train Loss: 0.3547, Validation Accuracy: 0.7868\nEpoch 06: Train Loss: 0.3021, Validation Accuracy: 0.7858\nEpoch 07: Train Loss: 0.2573, Validation Accuracy: 0.8002\nEpoch 08: Train Loss: 0.2199, Validation Accuracy: 0.8091\nEpoch 09: Train Loss: 0.1843, Validation Accuracy: 0.8106\nEpoch 10: Train Loss: 0.1572, Validation Accuracy: 0.8091\nEpoch 11: Train Loss: 0.1339, Validation Accuracy: 0.8185\nEpoch 12: Train Loss: 0.1127, Validation Accuracy: 0.8195\nEpoch 13: Train Loss: 0.0984, Validation Accuracy: 0.8204\nEpoch 14: Train Loss: 0.0847, Validation Accuracy: 0.8165\nEpoch 15: Train Loss: 0.0700, Validation Accuracy: 0.8265\nEpoch 16: Train Loss: 0.0569, Validation Accuracy: 0.8265\nEpoch 17: Train Loss: 0.0474, Validation Accuracy: 0.8334\nEpoch 18: Train Loss: 0.0398, Validation Accuracy: 0.8331\nEpoch 19: Train Loss: 0.0364, Validation Accuracy: 0.8326\nEpoch 20: Train Loss: 0.0318, Validation Accuracy: 0.8301\nEpoch 21: Train Loss: 0.0281, Validation Accuracy: 0.8338\nEpoch 22: Train Loss: 0.0261, Validation Accuracy: 0.8334\nEpoch 23: Train Loss: 0.0213, Validation Accuracy: 0.8314\nEpoch 24: Train Loss: 0.0183, Validation Accuracy: 0.8347\nEpoch 25: Train Loss: 0.0153, Validation Accuracy: 0.8342\nEpoch 26: Train Loss: 0.0141, Validation Accuracy: 0.8358\nEpoch 27: Train Loss: 0.0120, Validation Accuracy: 0.8332\nEpoch 28: Train Loss: 0.0101, Validation Accuracy: 0.8351\nEpoch 29: Train Loss: 0.0087, Validation Accuracy: 0.8360\nEpoch 30: Train Loss: 0.0088, Validation Accuracy: 0.8266\nEpoch 31: Train Loss: 0.0083, Validation Accuracy: 0.8323\nEpoch 32: Train Loss: 0.0076, Validation Accuracy: 0.8300\nEpoch 33: Train Loss: 0.0071, Validation Accuracy: 0.8353\nEpoch 34: Train Loss: 0.0058, Validation Accuracy: 0.8362\nEpoch 35: Train Loss: 0.0052, Validation Accuracy: 0.8367\nEpoch 36: Train Loss: 0.0065, Validation Accuracy: 0.7708\nEpoch 37: Train Loss: 0.0522, Validation Accuracy: 0.7715\nEpoch 38: Train Loss: 0.0851, Validation Accuracy: 0.7721\nEpoch 39: Train Loss: 0.0864, Validation Accuracy: 0.8021\nEpoch 40: Train Loss: 0.0716, Validation Accuracy: 0.8199\nEpoch 41: Train Loss: 0.0478, Validation Accuracy: 0.8276\nEpoch 42: Train Loss: 0.0324, Validation Accuracy: 0.8260\nEpoch 43: Train Loss: 0.0236, Validation Accuracy: 0.8340\nEpoch 44: Train Loss: 0.0157, Validation Accuracy: 0.8354\nEpoch 45: Train Loss: 0.0111, Validation Accuracy: 0.8372\nEpoch 46: Train Loss: 0.0085, Validation Accuracy: 0.8381\nEpoch 47: Train Loss: 0.0073, Validation Accuracy: 0.8396\nEpoch 48: Train Loss: 0.0059, Validation Accuracy: 0.8388\nEpoch 49: Train Loss: 0.0050, Validation Accuracy: 0.8399\nEpoch 50: Train Loss: 0.0046, Validation Accuracy: 0.8400\nTest Accuracy: 0.8454\n","output_type":"stream"}],"execution_count":15}]}