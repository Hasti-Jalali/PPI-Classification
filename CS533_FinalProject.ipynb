{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaXXZMwmuCdKslN3icFOx2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YYfI7KphZO0h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/drive/MyDrive/3D Computer Vision/final_project"
      ],
      "metadata": {
        "id": "qSs3h8IMZQGF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clRnZnnLZUVf",
        "outputId": "ae0a265e-d00e-41ad-c20d-29580815b66e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv, JumpingKnowledge, GCNConv\n",
        "from torch_geometric.datasets import PPI\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import dense_to_sparse"
      ],
      "metadata": {
        "id": "nWhbtBwD-jFJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Student Model\n",
        "# -------------------------\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, use_jk=False):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.use_jk = use_jk\n",
        "\n",
        "        # GIN Layers\n",
        "        self.gin_convs = nn.ModuleList()\n",
        "        self.gin_convs.append(\n",
        "            GINConv(nn.Sequential(\n",
        "                nn.Linear(in_channels, hidden_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_channels, hidden_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(hidden_channels)\n",
        "            ))\n",
        "        )\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.gin_convs.append(\n",
        "                GINConv(nn.Sequential(\n",
        "                    nn.Linear(hidden_channels, hidden_channels),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hidden_channels, hidden_channels),\n",
        "                    nn.ReLU(),\n",
        "                    nn.BatchNorm1d(hidden_channels)\n",
        "                ))\n",
        "            )\n",
        "\n",
        "        # Jumping Knowledge (optional)\n",
        "        if self.use_jk:\n",
        "            self.jk = JumpingKnowledge(mode='cat')\n",
        "            self.lin1 = nn.Linear(num_layers * hidden_channels, hidden_channels)\n",
        "        else:\n",
        "            self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "        # Label embeddings\n",
        "        self.label_embeddings = nn.Parameter(torch.randn(out_channels, hidden_channels))  # Learnable label embeddings\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        embeddings = []\n",
        "        for conv in self.gin_convs:\n",
        "            x = conv(x, edge_index)\n",
        "            embeddings.append(x)\n",
        "\n",
        "        if self.use_jk:\n",
        "            x = self.jk(embeddings)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)  # Output node classification logits\n",
        "        return x"
      ],
      "metadata": {
        "id": "cQW9rML8-pfZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Teacher Model\n",
        "# -------------------------\n",
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self, student_model):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        # Clone student model structure\n",
        "        self.model = StudentModel(\n",
        "            in_channels=student_model.gin_convs[0].nn[0].in_features,\n",
        "            hidden_channels=student_model.gin_convs[0].nn[0].out_features,\n",
        "            out_channels=student_model.lin2.out_features,\n",
        "            num_layers=len(student_model.gin_convs),\n",
        "            use_jk=student_model.use_jk\n",
        "        )\n",
        "        self.model.load_state_dict(student_model.state_dict())  # Initialize with student weights\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update(self, student_model, alpha=0.99):\n",
        "        \"\"\"Update teacher parameters using EMA.\"\"\"\n",
        "        for teacher_param, student_param in zip(self.model.parameters(), student_model.parameters()):\n",
        "            teacher_param.data = alpha * teacher_param.data + (1 - alpha) * student_param.data\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.model(x, edge_index)"
      ],
      "metadata": {
        "id": "psAdlsnM-r1o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Semi-Supervised Loss Function\n",
        "# -------------------------\n",
        "def graph_consistency_loss(student_out, teacher_out, mask):\n",
        "    \"\"\"Calculate consistency loss using adjacency similarity.\"\"\"\n",
        "    student_probs = F.softmax(student_out[mask], dim=1)\n",
        "    teacher_probs = F.softmax(teacher_out[mask], dim=1)\n",
        "\n",
        "    student_adj = torch.mm(student_probs, student_probs.T)\n",
        "    teacher_adj = torch.mm(teacher_probs, teacher_probs.T)\n",
        "\n",
        "    return F.mse_loss(student_adj, teacher_adj)\n",
        "\n",
        "def semi_supervised_loss(student_out, teacher_out, labels, labeled_mask, unlabeled_mask, lambda_con=0.1):\n",
        "    \"\"\"Combined supervised and consistency loss.\"\"\"\n",
        "    # sup_loss = F.cross_entropy(student_out[labeled_mask], labels[labeled_mask])\n",
        "    # sup_loss = torch.nn.BCEWithLogitsLoss(student_out[labeled_mask], labels[labeled_mask])\n",
        "    bce_loss = nn.BCEWithLogitsLoss()\n",
        "    sup_loss = bce_loss(student_out[labeled_mask], labels[labeled_mask])\n",
        "\n",
        "    con_loss = graph_consistency_loss(student_out, teacher_out, unlabeled_mask)\n",
        "    return sup_loss + lambda_con * con_loss"
      ],
      "metadata": {
        "id": "-BmOAYtP-tr6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Training Framework\n",
        "# -------------------------\n",
        "class SemiGNNFrameworkPPI:\n",
        "    def __init__(self, student_model, teacher_model, device):\n",
        "        self.student = student_model.to(device)\n",
        "        self.teacher = teacher_model.to(device)\n",
        "        self.device = device\n",
        "        self.optimizer = torch.optim.Adam(self.student.parameters(), lr=0.005)\n",
        "        self.lambda_con = 0.1\n",
        "\n",
        "    def train_step(self, loader):\n",
        "        \"\"\"Train student and update teacher model.\"\"\"\n",
        "        self.student.train()\n",
        "        self.teacher.eval()\n",
        "        total_loss = 0\n",
        "\n",
        "        for data in loader:\n",
        "            data = data.to(self.device)\n",
        "            labeled_mask = data.train_mask\n",
        "            unlabeled_mask = ~data.train_mask\n",
        "\n",
        "            # Forward pass\n",
        "            student_out = self.student(data.x, data.edge_index)\n",
        "            with torch.no_grad():\n",
        "                teacher_out = self.teacher(data.x, data.edge_index)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = semi_supervised_loss(student_out, teacher_out, data.y, labeled_mask, unlabeled_mask, self.lambda_con)\n",
        "\n",
        "            # Backpropagation\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Update teacher model\n",
        "        self.teacher.update(self.student)\n",
        "        return total_loss / len(loader)\n",
        "\n",
        "\n",
        "    def evaluate(self, loader):\n",
        "      \"\"\"Evaluate the student model for multi-label node classification.\"\"\"\n",
        "      self.student.eval()\n",
        "      total_correct, total_labels = 0, 0\n",
        "\n",
        "      for data in loader:\n",
        "          data = data.to(self.device)\n",
        "          with torch.no_grad():\n",
        "              out = self.student(data.x, data.edge_index)  # Raw logits\n",
        "              prob = torch.sigmoid(out)                   # Probabilities (0 to 1)\n",
        "              pred = (prob > 0.5).long()                  # Binarize predictions\n",
        "              # print(data.val_mask.shape)\n",
        "              # print(pred.shape)\n",
        "              # print(data.y.shape)\n",
        "\n",
        "              # Validation mask and multi-label accuracy\n",
        "              correct = (pred == data.y).sum().item()\n",
        "              total_correct += correct\n",
        "              total_labels += data.y.size(0) * data.y.size(1)  # Total labels (nodes * 121)\n",
        "\n",
        "      accuracy = total_correct / total_labels\n",
        "      return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "_U7Qjgss-2QH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Main Script\n",
        "# -------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Load PPI dataset\n",
        "train_dataset = PPI(root='data/PPI', split='train')\n",
        "val_dataset = PPI(root='data/PPI', split='val')\n",
        "test_dataset = PPI(root='data/PPI', split='test')\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def create_train_mask(data, train_ratio=0.9):\n",
        "    \"\"\"\n",
        "    Create a train_mask for nodes in a graph.\n",
        "    :param data: A graph in the PPI dataset (torch_geometric.data.Data).\n",
        "    :param train_ratio: Fraction of nodes to use for training.\n",
        "    :return: train_mask (torch.Tensor)\n",
        "    \"\"\"\n",
        "    num_nodes = data.x.size(0)  # Total number of nodes\n",
        "    num_train = int(train_ratio * num_nodes)  # Number of training nodes\n",
        "\n",
        "    # Randomly permute indices and select train nodes\n",
        "    perm = torch.randperm(num_nodes)\n",
        "    train_indices = perm[:num_train]\n",
        "\n",
        "    # Initialize train_mask\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    train_mask[train_indices] = True\n",
        "    return train_mask\n",
        "\n",
        "# Update train_dataset with train_mask\n",
        "updated_train_dataset = []\n",
        "for graph in train_dataset:\n",
        "    train_mask = create_train_mask(graph, train_ratio=0.05)\n",
        "    updated_graph = Data(\n",
        "        x=graph.x,\n",
        "        edge_index=graph.edge_index,\n",
        "        y=graph.y,\n",
        "        train_mask=train_mask\n",
        "    )\n",
        "    updated_train_dataset.append(updated_graph)\n",
        "\n",
        "\n",
        "# print(f\"Train_mask example: {updated_train_dataset[0].train_mask}\")\n",
        "\n",
        "train_loader = DataLoader(updated_train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# Initialize models\n",
        "student_model = StudentModel(in_channels=train_dataset.num_features, hidden_channels=512,\n",
        "                             out_channels=train_dataset.num_classes, num_layers=3, use_jk=True)\n",
        "teacher_model = TeacherModel(student_model)\n",
        "\n",
        "# Initialize framework\n",
        "framework = SemiGNNFrameworkPPI(student_model, teacher_model, device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    train_loss = framework.train_step(train_loader)\n",
        "    val_accuracy = framework.evaluate(val_loader)\n",
        "    print(f\"Epoch {epoch+1:02d}: Train Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Testing\n",
        "test_accuracy = framework.evaluate(test_loader)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkBODMuYwaxu",
        "outputId": "9a2c26f6-18b5-48df-a346-af504b0c5ee1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: Train Loss: 0.5895, Validation Accuracy: 0.7262\n",
            "Epoch 02: Train Loss: 0.5047, Validation Accuracy: 0.7517\n",
            "Epoch 03: Train Loss: 0.4434, Validation Accuracy: 0.7785\n",
            "Epoch 04: Train Loss: 0.3836, Validation Accuracy: 0.7764\n",
            "Epoch 05: Train Loss: 0.3259, Validation Accuracy: 0.7845\n",
            "Epoch 06: Train Loss: 0.2781, Validation Accuracy: 0.7979\n",
            "Epoch 07: Train Loss: 0.2381, Validation Accuracy: 0.7968\n",
            "Epoch 08: Train Loss: 0.2147, Validation Accuracy: 0.7870\n",
            "Epoch 09: Train Loss: 0.1820, Validation Accuracy: 0.8094\n",
            "Epoch 10: Train Loss: 0.1541, Validation Accuracy: 0.8099\n",
            "Epoch 11: Train Loss: 0.1301, Validation Accuracy: 0.8150\n",
            "Epoch 12: Train Loss: 0.1169, Validation Accuracy: 0.8087\n",
            "Epoch 13: Train Loss: 0.1108, Validation Accuracy: 0.8122\n",
            "Epoch 14: Train Loss: 0.0981, Validation Accuracy: 0.8224\n",
            "Epoch 15: Train Loss: 0.0809, Validation Accuracy: 0.8235\n",
            "Epoch 16: Train Loss: 0.0666, Validation Accuracy: 0.8253\n",
            "Epoch 17: Train Loss: 0.0550, Validation Accuracy: 0.8295\n",
            "Epoch 18: Train Loss: 0.0440, Validation Accuracy: 0.8270\n",
            "Epoch 19: Train Loss: 0.0347, Validation Accuracy: 0.8311\n",
            "Epoch 20: Train Loss: 0.0313, Validation Accuracy: 0.8217\n",
            "Epoch 21: Train Loss: 0.0340, Validation Accuracy: 0.8235\n",
            "Epoch 22: Train Loss: 0.0314, Validation Accuracy: 0.8244\n",
            "Epoch 23: Train Loss: 0.0304, Validation Accuracy: 0.8279\n",
            "Epoch 24: Train Loss: 0.0253, Validation Accuracy: 0.8289\n",
            "Epoch 25: Train Loss: 0.0220, Validation Accuracy: 0.8310\n",
            "Epoch 26: Train Loss: 0.0184, Validation Accuracy: 0.8318\n",
            "Epoch 27: Train Loss: 0.0144, Validation Accuracy: 0.8316\n",
            "Epoch 28: Train Loss: 0.0124, Validation Accuracy: 0.8339\n",
            "Epoch 29: Train Loss: 0.0116, Validation Accuracy: 0.8349\n",
            "Epoch 30: Train Loss: 0.0113, Validation Accuracy: 0.8325\n",
            "Epoch 31: Train Loss: 0.0089, Validation Accuracy: 0.8332\n",
            "Epoch 32: Train Loss: 0.0079, Validation Accuracy: 0.8329\n",
            "Epoch 33: Train Loss: 0.0078, Validation Accuracy: 0.8341\n",
            "Epoch 34: Train Loss: 0.0081, Validation Accuracy: 0.8278\n",
            "Epoch 35: Train Loss: 0.0144, Validation Accuracy: 0.8252\n",
            "Epoch 36: Train Loss: 0.0175, Validation Accuracy: 0.8272\n",
            "Epoch 37: Train Loss: 0.0216, Validation Accuracy: 0.8234\n",
            "Epoch 38: Train Loss: 0.0245, Validation Accuracy: 0.8237\n",
            "Epoch 39: Train Loss: 0.0230, Validation Accuracy: 0.8257\n",
            "Epoch 40: Train Loss: 0.0233, Validation Accuracy: 0.8272\n",
            "Epoch 41: Train Loss: 0.0230, Validation Accuracy: 0.8268\n",
            "Epoch 42: Train Loss: 0.0240, Validation Accuracy: 0.8260\n",
            "Epoch 43: Train Loss: 0.0233, Validation Accuracy: 0.8210\n",
            "Epoch 44: Train Loss: 0.0215, Validation Accuracy: 0.8277\n",
            "Epoch 45: Train Loss: 0.0207, Validation Accuracy: 0.8254\n",
            "Epoch 46: Train Loss: 0.0195, Validation Accuracy: 0.8281\n",
            "Epoch 47: Train Loss: 0.0140, Validation Accuracy: 0.8293\n",
            "Epoch 48: Train Loss: 0.0118, Validation Accuracy: 0.8306\n",
            "Epoch 49: Train Loss: 0.0088, Validation Accuracy: 0.8332\n",
            "Epoch 50: Train Loss: 0.0075, Validation Accuracy: 0.8317\n",
            "Test Accuracy: 0.8376\n"
          ]
        }
      ]
    }
  ]
}